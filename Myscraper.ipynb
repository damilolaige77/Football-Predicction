{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ezSUUN2Ks6hq"
      },
      "outputs": [],
      "source": [
        "#import libaries\n",
        "import random\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base URL of fbref.com Premier League season stats\n",
        "base_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n",
        "seasons = [\n",
        "    '2023-2024',\n",
        "    '2022-2023',\n",
        "    '2021-2022',\n",
        "    '2020-2021',\n",
        "    '2019-2020',\n",
        "    '2018-2019',\n",
        "    '2017-2018',\n",
        "    '2016-2017',\n",
        "    '2015-2016',\n",
        "    '2014-2015',\n",
        "]"
      ],
      "metadata": {
        "id": "EKfLYHhXs-Y5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_season_data(season, max_retries=3):\n",
        "    url = f\"{base_url}/{season}/{season}-Premier-League-Stats\"  # Corrected URL format\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes\n",
        "            print(f\"Response status code for {season}: {response.status_code}\")\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            table = soup.find('table', {'class': 'stats_table'})  # Check if this selector is still valid\n",
        "            return table\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching data for {season}: {e}\")\n",
        "            retries += 1\n",
        "            sleep_time = random.uniform(5, 10)  # Random sleep between 5 to 10 seconds\n",
        "            print(f\"Retrying in {sleep_time:.2f} seconds...\")\n",
        "            time.sleep(sleep_time)\n",
        "    print(f\"Failed to fetch data for {season} after {max_retries} retries.\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "ui8d_WyOtM36"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store dataframes for each season\n",
        "all_seasons_data = []"
      ],
      "metadata": {
        "id": "2AJHRiVrtM6l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for season in seasons:\n",
        "    table = scrape_season_data(season)\n",
        "    if table:\n",
        "        # Extract headers\n",
        "        headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
        "\n",
        "        # Remove unnecessary headers\n",
        "        if \"Notes\" in headers:\n",
        "            headers.remove(\"Notes\")\n",
        "        if \"Rk\" in headers:\n",
        "            headers.remove(\"Rk\")\n",
        "\n",
        "        rows = table.find('tbody').find_all('tr')\n",
        "        season_data = [\n",
        "            [td.text.strip() for td in row.find_all('td') if td.text.strip()]\n",
        "            for row in rows\n",
        "        ]\n",
        "\n",
        "        # Check for length mismatch and handle it\n",
        "        for row in season_data:\n",
        "            if len(row) != len(headers):\n",
        "                print(f\"Warning: Column mismatch for season {season}. Row data length: {len(row)}, Headers length: {len(headers)}\")\n",
        "                # You can decide to skip this row, pad it, or take other actions based on your requirements.\n",
        "\n",
        "        # Create and append the DataFrame\n",
        "        df = pd.DataFrame(season_data, columns=headers)\n",
        "        df['Season'] = season  # Add the 'Season' column\n",
        "        all_seasons_data.append(df)\n",
        "        print(f\"Dataframe for season {season} created and appended.\")\n",
        "    else:\n",
        "        print(f\"No table found for season: {season}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So3_CUUDtM9Q",
        "outputId": "573f142a-d20c-4fd4-f345-7026e7ee4970"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response status code for 2023-2024: 200\n",
            "Dataframe for season 2023-2024 created and appended.\n",
            "Response status code for 2022-2023: 200\n",
            "Dataframe for season 2022-2023 created and appended.\n",
            "Response status code for 2021-2022: 200\n",
            "Dataframe for season 2021-2022 created and appended.\n",
            "Response status code for 2020-2021: 200\n",
            "Dataframe for season 2020-2021 created and appended.\n",
            "Response status code for 2019-2020: 200\n",
            "Dataframe for season 2019-2020 created and appended.\n",
            "Response status code for 2018-2019: 200\n",
            "Dataframe for season 2018-2019 created and appended.\n",
            "Response status code for 2017-2018: 200\n",
            "Dataframe for season 2017-2018 created and appended.\n",
            "Response status code for 2016-2017: 200\n",
            "Dataframe for season 2016-2017 created and appended.\n",
            "Response status code for 2015-2016: 200\n",
            "Dataframe for season 2015-2016 created and appended.\n",
            "Response status code for 2014-2015: 200\n",
            "Dataframe for season 2014-2015 created and appended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all season DataFrames\n",
        "all_seasons_df = pd.concat(all_seasons_data, ignore_index=True)\n",
        "\n",
        "# Encoding\n",
        "all_seasons_encoded = []\n",
        "for df in all_seasons_data:\n",
        "    # Create a LabelEncoder object\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # Fit the encoder to the 'Squad' column and transform it\n",
        "    df['Squad_Encoded'] = le.fit_transform(df['Squad'])\n",
        "    # Ordinal Encoding for 'Season' column\n",
        "    df['season_ordinal'] = df['Season'].apply(lambda x: int(x.split('-')[0]))  # Corrected to split by '-'\n",
        "\n",
        "    # Append the modified DataFrame to the new list\n",
        "    all_seasons_encoded.append(df)\n",
        "\n",
        "# Save the concatenated DataFrame to a CSV file\n",
        "all_seasons_df.to_csv(\"premierleague.csv\", index=False)\n",
        "print(\"Data saved to premierleague.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aho67cDWtrkO",
        "outputId": "0b21d8ec-6e23-4291-ba3e-22da43dab4a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to premierleague.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZONLghKtNAP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}